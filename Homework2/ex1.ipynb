{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import argparse\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#classes:\r\n",
    "\r\n",
    "#window generator class:\r\n",
    "class WindowGenerator:\r\n",
    "    def __init__(self, input_width, output_width, mean, std):\r\n",
    "        self.input_width = input_width\r\n",
    "        self.output_width = output_width\r\n",
    "        self.label_options = label_options\r\n",
    "        self.mean = tf.reshape(tf.convert_to_tensor(mean), [1, 1, 2])\r\n",
    "        self.std = tf.reshape(tf.convert_to_tensor(std), [1, 1, 2])\r\n",
    "\r\n",
    "    def split_window(self, features):\r\n",
    "        inputs = features[:, :-self.output_width, :]\r\n",
    "\r\n",
    "        labels = features[:, -self.output_width, :]\r\n",
    "\r\n",
    "        inputs.set_shape([None, self.input_width, 2])\r\n",
    "        labels.set_shape([None, self.output_width, 2])\r\n",
    "\r\n",
    "        return inputs, labels\r\n",
    "\r\n",
    "    def normalize(self, features):\r\n",
    "        features = (features - self.mean) / (self.std + 1.e-6)\r\n",
    "\r\n",
    "        return features\r\n",
    "\r\n",
    "    def preprocess(self, features):\r\n",
    "        inputs, labels = self.split_window(features)\r\n",
    "        inputs = self.normalize(inputs)\r\n",
    "        return inputs, labels\r\n",
    "\r\n",
    "    def make_dataset(self, data, train):\r\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\r\n",
    "                data=data,\r\n",
    "                targets=None,\r\n",
    "                sequence_length=input_width+output_width,\r\n",
    "                sequence_stride=1,\r\n",
    "                batch_size=32)\r\n",
    "        ds = ds.map(self.preprocess)\r\n",
    "        ds = ds.cache()\r\n",
    "        if train is True:\r\n",
    "            ds = ds.shuffle(100, reshuffle_each_iteration=True)\r\n",
    "\r\n",
    "        return ds\r\n",
    "\r\n",
    "\r\n",
    "#Multi output class for MAE:\r\n",
    "class MultipleOutputforMAE(tf.keras.metrics.Metric):\r\n",
    "  def __init__(self, name='MAE', **kwargs):\r\n",
    "      super().__init__(name=name, **kwargs)\r\n",
    "      self.total = self.add_weight(name='total', initializer='zeros',shape=(2,))\r\n",
    "      self.count = self.add_weight('count',initializer = 'zeros')\r\n",
    "  def update_state(self, y_true, y_pred, sample_weight=None):\r\n",
    "    error = tf.abs(y_pred - y_true)\r\n",
    "    error = tf.reduce_mean(error,axis = 0)\r\n",
    "    self.total.assign_add(error)\r\n",
    "    self.count.assign_add(1.)\r\n",
    "\r\n",
    "  def reset_states(self):\r\n",
    "    self.count.assign(tf.zeros_like(self.count))\r\n",
    "    self.total.assign(tf.zeros_like(self.total))\r\n",
    "    return\r\n",
    "\r\n",
    "  def result(self):\r\n",
    "    result = tf.math.divide_no_nan(self.total,self.count)\r\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#input arguments:\r\n",
    "parser = argparse.ArgumentParser()\r\n",
    "parser.add_argument('--version', type=str, required=True, help='model name')\r\n",
    "parser.add_argument('--number_epochs', type=int, required=False, default=1, help='number of epochs')\r\n",
    "args = parser.parse_args()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "usage: ipykernel_launcher [-h] --version VERSION\n",
      "                          [--number_epochs NUMBER_EPOCHS]\n",
      "ipykernel_launcher: error: the following arguments are required: --version\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "2",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\imanp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3452: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\r\n",
    "#defining changes for different versions:\r\n",
    "if(args.version == 'a'):\r\n",
    "    output_width = 3\r\n",
    "    \r\n",
    "    #mlp model:\r\n",
    "    MLPmodel = keras.Sequential([\r\n",
    "    keras.layers.Flatten(),\r\n",
    "    keras.layers.Dense(128, activation='relu'),\r\n",
    "    keras.layers.Dense(128, activation='relu'),\r\n",
    "    keras.layers.Dense(2)\r\n",
    "    ])\r\n",
    "\r\n",
    "    #cnn model:\r\n",
    "    CNNmodel = keras.Sequential([\r\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=3,activation='relu'),\r\n",
    "    keras.layers.Flatten(),\r\n",
    "    keras.layers.Dense(64, activation='relu'),\r\n",
    "    keras.layers.Dense(1)\r\n",
    "    ])\r\n",
    "\r\n",
    "    #LSTM model:\r\n",
    "    LSTMmodel = keras.Sequential([\r\n",
    "    keras.layers.LSTM(units=64),\r\n",
    "    keras.layers.Flatten(),\r\n",
    "    keras.layers.Dense(1)\r\n",
    "    ])\r\n",
    "\r\n",
    "if(args.version == 'b'):\r\n",
    "    output_width = 9\r\n",
    "\r\n",
    "    #mlp model:\r\n",
    "    MLPmodel = keras.Sequential([\r\n",
    "    keras.layers.Flatten(),\r\n",
    "    keras.layers.Dense(128, activation='relu'),\r\n",
    "    keras.layers.Dense(128, activation='relu'),\r\n",
    "    keras.layers.Dense(2)\r\n",
    "    ])\r\n",
    "\r\n",
    "    #cnn model:\r\n",
    "    CNNmodel = keras.Sequential([\r\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=3,activation='relu'),\r\n",
    "    keras.layers.Flatten(),\r\n",
    "    keras.layers.Dense(64, activation='relu'),\r\n",
    "    keras.layers.Dense(1)\r\n",
    "    ])\r\n",
    "\r\n",
    "    #LSTM model:\r\n",
    "    LSTMmodel = keras.Sequential([\r\n",
    "    keras.layers.LSTM(units=64),\r\n",
    "    keras.layers.Flatten(),\r\n",
    "    keras.layers.Dense(1)\r\n",
    "    ])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21592/568703864.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#defining changes for different versions:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0moutput_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#mlp model:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#defining seed to have consistent results\r\n",
    "seed = 42\r\n",
    "tf.random.set_seed(seed)\r\n",
    "np.random.seed(seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#reading the files:\r\n",
    "csv_path = 'jena_climate_2009_2016.csv'\r\n",
    "df = pd.read_csv(csv_path)\r\n",
    "column_indices = [2, 5]\r\n",
    "columns = df.columns[column_indices]\r\n",
    "data = df[columns].values.astype(np.float32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#sperating train,val,test:\r\n",
    "n = len(data)\r\n",
    "train_data = data[0:int(n*0.7)]\r\n",
    "val_data = data[int(n*0.7):int(n*0.9)]\r\n",
    "test_data = data[int(n*0.9):]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#defining important variables:\r\n",
    "mean = train_data.mean(axis=0)\r\n",
    "std = train_data.std(axis=0)\r\n",
    "input_width = 6"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#make the datasets:\r\n",
    "generator = WindowGenerator(input_width, output_width, mean, std)\r\n",
    "train_ds = generator.make_dataset(train_data, True)\r\n",
    "val_ds = generator.make_dataset(val_data, False)\r\n",
    "test_ds = generator.make_dataset(test_data, False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#choose the metric system:\r\n",
    "metrics = [MultipleOutputforMAE()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#compiling models:\r\n",
    "MLPmodel.compile(optimizer='adam',\r\n",
    "              loss=tf.keras.losses.MAE,\r\n",
    "              metrics=metrics)\r\n",
    "\r\n",
    "CNNmodel.compile(optimizer='adam',\r\n",
    "              loss=tf.keras.losses.MAE,\r\n",
    "              metrics=metrics)\r\n",
    "\r\n",
    "LSTMmodel.compile(optimizer='adam',\r\n",
    "              loss=tf.keras.losses.MAE,\r\n",
    "              metrics=metrics)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#running the models:\r\n",
    "print(\"starting MLP\")\r\n",
    "MLPmodel.fit(train_ds, epochs=args.number_epochs)\r\n",
    "print(\"MLP done\")\r\n",
    "print(\"starting CNNmodel\")\r\n",
    "CNNmodel.fit(train_ds, epochs=args.number_epochs)\r\n",
    "LSTMmodel.fit(train_ds, epochs=args.number_epochs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_loss, test_acc = MLPmodel.evaluate(test_ds, verbose=0)\r\n",
    "print('\\n MSE for MLP :', test_acc)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "ad4a7f633457edeca986db117c49439398b3575b7cfc8b89bb9541a12d05f016"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}